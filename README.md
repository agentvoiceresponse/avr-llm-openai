# Agent Voice Response - OpenAI Integration

This repository showcases the integration between **Agent Voice Response** and **OpenAI**. The application leverages OpenAI's powerful language model to process text input from users, providing intelligent, context-aware responses that enhance the virtual agent's capabilities.

## Prerequisites

To set up and run this project, you will need:

1. **Node.js** and **npm** installed.
2. An **OpenAI API key**.

## Setup

### 1. Clone the Repository

```bash
git clone https://github.com/agentvoiceresponse/avr-llm-openai.git
cd aavr-llm-openai
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env` file in the root of the project to store your API keys and configuration. You will need to add the following variables:

```bash
OPENAI_API_KEY=your_openai_api_key
PORT=6002
```

Replace `your_openai_api_key` with your actual OpenAI API key.

### 4. Running the Application

Start the application by running the following command:

```bash
node index.js
```

The server will start on the port defined in the environment variable (default: 6002).

## How It Works

The **Agent Voice Response** system integrates with OpenAI to provide intelligent text-based responses to user queries. The server receives text input from users, forwards it to OpenAI's API, and then returns the model's response to the user in real time. This allows the virtual agent to simulate conversational abilities, improving the overall user experience.

### Key Components

- **Express.js Server**: The server handles incoming requests from clients and sends them to OpenAIâ€™s API for processing.
- **OpenAI API Integration**: The application sends text queries to OpenAI and receives generated responses, which are relayed back to the user.
- **Conversation Handling**: The system can maintain the context of conversations for more interactive and dynamic exchanges.

### Example Code Overview

1. **OpenAI API Request**: The application sends user input to OpenAI and specifies the model (e.g., `gpt-4`) to be used for generating responses.
2. **Response Streaming**: The server streams the response back to the client, allowing real-time interaction.
3. **Conversation Context**: You can implement conversation handling by storing previous interactions and passing them as part of the prompt for more contextual responses.

## API Endpoints

### POST `/prompt-stream`

This endpoint accepts a JSON payload containing the user's messages and returns a response generated by OpenAI.

## Customizing OpenAI API Requests

In `index.js`, you can modify the parameters sent to OpenAI, such as changing the model or adjusting the `temperature` and `max_tokens` to control the creativity and length of the responses:

```javascript
const openaiRequest = {
  model: "gpt-4",
  prompt: query,
  temperature: 0.7,
  max_tokens: 150,
};
```
